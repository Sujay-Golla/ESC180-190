{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def norm(vec):\n",
        "    '''Return the norm of a vector stored as a dictionary, as\n",
        "    described in the handout for Project 3.\n",
        "    '''\n",
        "\n",
        "    sum_of_squares = 0.0\n",
        "    for x in vec:\n",
        "        sum_of_squares += vec[x] * vec[x]\n",
        "\n",
        "    return math.sqrt(sum_of_squares)\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    denom = norm(vec1) * norm(vec2)\n",
        "    numer = 0\n",
        "    for x in vec1:\n",
        "        if x in vec2:\n",
        "            numer += vec1[x] * vec2[x]\n",
        "    return numer / denom\n",
        "\n",
        "def build_semantic_descriptors(sentences):\n",
        "    descriptors = {}\n",
        "    for sentence in sentences:\n",
        "        words = {}\n",
        "\n",
        "        for word in sentence:\n",
        "            if word not in words:\n",
        "                words[word] = 1\n",
        "\n",
        "        for word in sentence:\n",
        "            temp = {}\n",
        "            temp.update(words)\n",
        "            temp.pop(word)\n",
        "            if word not in descriptors:\n",
        "                descriptors[word] = temp\n",
        "            else:\n",
        "                for w in temp:\n",
        "                    if w in descriptors[word]:\n",
        "                        descriptors[word][w] += 1\n",
        "                    else:\n",
        "                        descriptors[word][w] = 1\n",
        "\n",
        "    return descriptors\n",
        "\n",
        "def build_semantic_descriptors_from_files(filenames):\n",
        "    combined_descriptors = {}\n",
        "    for file in filenames:\n",
        "        sentences = []\n",
        "        text = open(file, \"r\", encoding=\"latin1\").read()\n",
        "        temp = \"\"\n",
        "        for c in text:\n",
        "            if c == \".\" or c == \"!\" or c == \"?\":\n",
        "                stripped = \"\"\n",
        "                for ch in temp:\n",
        "                    if ch not in [\",\", \"-\", \"â€”\", \"--\", \":\", \";\", '\"', \"'\", \"...\", \"*\", \"(\", \")\", \"/\"]:\n",
        "                        stripped += ch\n",
        "                    else:\n",
        "                        stripped += \" \"\n",
        "                sentences.append(stripped.strip().lower().split(\" \"))\n",
        "                temp = \"\"\n",
        "            else:\n",
        "                temp += c\n",
        "        descriptors = build_semantic_descriptors(sentences)\n",
        "\n",
        "        for word in descriptors.keys():\n",
        "            if word not in combined_descriptors.keys():\n",
        "                temp = {}\n",
        "                temp.update(descriptors[word])\n",
        "                combined_descriptors[word] = temp\n",
        "            else:\n",
        "                for w in descriptors[word].keys():\n",
        "                    if w in combined_descriptors[word]:\n",
        "                        combined_descriptors[word][w] += descriptors[word][w]\n",
        "                    else:\n",
        "                        combined_descriptors[word][w] = descriptors[word][w]\n",
        "    return combined_descriptors\n",
        "\n",
        "def most_similar_word(word, choices, semantic_descriptors, similarity_fn):\n",
        "    similarity = []\n",
        "    for choice in choices:\n",
        "        keys = semantic_descriptors.keys()\n",
        "        if choice in keys and word in keys:\n",
        "            similarity.append(similarity_fn(semantic_descriptors[word], semantic_descriptors[choice]))\n",
        "        else:\n",
        "            similarity.append(-1)\n",
        "\n",
        "    max_sim = -2\n",
        "    most_sim = \"\"\n",
        "    for i in range(len(similarity)):\n",
        "        if similarity[i] > max_sim:\n",
        "            max_sim = similarity[i]\n",
        "            most_sim = choices[i]\n",
        "\n",
        "    return most_sim\n",
        "\n",
        "def run_similarity_test(filename, semantic_descriptors, similarity_fn):\n",
        "    lines = open(filename).read().split(\"\\n\")\n",
        "    tests = []\n",
        "    for line in lines:\n",
        "        tests.append(line.split(\" \"))\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for test in tests:\n",
        "        prediction = most_similar_word(test[0], test[2:], semantic_descriptors, similarity_fn)\n",
        "        if prediction == test[1]:\n",
        "            counter += 1\n",
        "\n",
        "    return counter*100/len(tests)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(cosine_similarity({'a':1, 'b':2, 'c':3}, {'b':4, 'c':5, 'd':6}))\n",
        "    dictionary = build_semantic_descriptors([[\"i\", \"am\", \"a\", \"sick\", \"man\"],\n",
        "                                            [\"i\", \"am\", \"a\", \"spiteful\", \"man\"],\n",
        "                                            [\"i\", \"am\", \"an\", \"unattractive\", \"man\"],\n",
        "                                            [\"i\", \"believe\", \"my\", \"liver\", \"is\", \"diseased\"],\n",
        "                                            [\"however\", \"i\", \"know\", \"nothing\", \"at\", \"all\", \"about\", \"my\",\n",
        "                                            \"disease\", \"and\", \"do\", \"not\", \"know\", \"for\", \"certain\", \"what\", \"ails\", \"me\"]])\n",
        "    print(dictionary['man'])\n",
        "    print(dictionary['liver'])\n",
        "    print(build_semantic_descriptors_from_files([\"test.txt\", \"test2.txt\"])[\"man\"])\n",
        "    print(build_semantic_descriptors_from_files([\"test.txt\", \"test2.txt\"])[\"liver\"])\n",
        "    print(most_similar_word(\"sick\", [\"spiteful\", \"unattractive\", \"liver\", \"diseased\", \"my\"], build_semantic_descriptors_from_files([\"test.txt\"]), cosine_similarity))\n",
        "\n",
        "    dictionary = build_semantic_descriptors_from_files([\"war_and_peace.txt\", \"swanns_way.txt\"])\n",
        "    print(run_similarity_test(\"trial.txt\", dictionary, cosine_similarity))\n",
        "    print(build_semantic_descriptors_from_files([\"test3.txt\"])[\"file\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45LixjGvmggv",
        "outputId": "e14b9908-77bd-47b3-d041-17a8a90eb5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7005166394541485\n",
            "{'i': 1, 'am': 1, 'a': 1, 'sick': 1, 'man': 1}\n",
            "{'i': 2, 'am': 1, 'a': 1, 'sick': 1, 'man': 1, 'believe': 1, 'my': 1, 'liver': 1, 'is': 1, 'diseased': 1}\n"
          ]
        }
      ]
    }
  ]
}